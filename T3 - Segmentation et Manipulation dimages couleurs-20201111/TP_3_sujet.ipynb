{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupe:\n",
    "\n",
    "1 - Nom, Prénom, Matricule:\n",
    "\n",
    "2 - Nom, Prénom, Matricule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce laboratoire est de se familiariser avec les notions de segmentation et de manipulation d'images couleurs. Pour cela, nous allons transformer une photographie réelle afin de lui donner un effet dessin. Deux étapes sont mises en oeuvre: la première est de détecter les contours dans l'image, pour donner un effet trait au feutre noir à notre dessin. La seconde consiste à réduire intelligemment le nombre de couleurs, de telle sorte à obtenir des régions uniformes.\n",
    "\n",
    "\n",
    "**Remise**: \n",
    "\n",
    "La date de remise est fixée au lundi 7 Décembre à 23h55. Une pénalité de 3 points par jour sera appliquée lors d'un retard.\n",
    "\n",
    "**Documents à remettre** :\n",
    "\n",
    "\n",
    "Les exercices doivent être codés dans ce fichier TP.ipynb. Les réponses aux questions doivent être inclues dans le code sous forme de commentaires ou dans des cellules dédiées (*Markdown* ou *text*). Les exercices doivent être séparés par des cellules, suivant le template fourni. Vous devez bien identifier chaque exercice et sous-question, et bien commenter le code. Veuillez nommer vos variables de manière explicite et assurez-vous que toutes les figures soient lisibles.\n",
    "\n",
    "Créer un fichier de rendu **html** (*Fichier -> Télécharger au format... -> HTML*)  de votre code et de vos graphiques. Veuillez remettre tous vos fichiers (.ipynb, html et autres) dans un seul fichier **zip** et nommez ce fichier selon vos matricules (Mat1\\_Mat2.zip).\n",
    "\n",
    "\n",
    "Une pénalité de 3 points sera appliquée si ces consignes ne sont pas respectées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports et utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray' # Choix de la color map par défaut, ne pas modifier\n",
    "import matplotlib\n",
    "import scipy.signal\n",
    "matplotlib.rcParams['figure.figsize'] = (25.0, 10.0) # Taille des figures par défaut, peut-être modifié au cas par cas.\n",
    "from scipy.cluster.vq import kmeans\n",
    "\n",
    "def imshow(img, title=None, ax=None, is_bgr=False, cmap='gray'):\n",
    "    \"\"\"\n",
    "    param img: image à afficher (soit hxwx3, soit hxw)\n",
    "    param title: Falcultatif. Titre du graphique\n",
    "    param ax: Falcultatif. axe sur lequel l'image sera affiché. Si aucun n'est donné, un nouvel axe sera créé.\n",
    "    param is_bgr: Pour une image couleur, si vraie, effectue la conversion BGR -> RGB\n",
    "    param cmap: Map de couleur utilisé pour afficher les images.\n",
    "    \"\"\"\n",
    "    show=False\n",
    "    plt.axis('off')\n",
    "    if ax is None:\n",
    "        show=True\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        ax = plt\n",
    "    else:\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "            ax.set_axis_off()\n",
    "    \n",
    "    if img.ndim==2:\n",
    "        ax.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        if is_bgr:\n",
    "            img = img[:,:,::-1].copy()\n",
    "        ax.imshow(img)\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def f2int(img):\n",
    "    return (img*255).astype(np.uint8)\n",
    "\n",
    "def int2f(img):\n",
    "    return img.astype(np.float32)/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1\n",
    "Qui dit dessin dit traits. La première partie de ce TP sera donc consacrée à la détection des contours de l'image, que nous assimilerons par la suite à des traits faits au feutre dans notre dessin. Pour afficher les images, nous vous fournissons une fonction **imshow** (voir la cellule ci-dessus) que vous pouvez utiliser au choix.\n",
    "\n",
    "## Question 1\n",
    "\n",
    "\n",
    "\n",
    "Chargez l'image **chat.png**, convertissez-la en valeurs flottantes et affichez-la.\n",
    "\n",
    "\n",
    "\n",
    "Assurez-vous que les couleurs soient correctement rendues (i.e: telles qu'elles apparaissent dans votre navigateur d'image) et que tous les pixels soient compris dans l'intervalle [0,1].\n",
    "\n",
    "> **Attention** Si vous utilisez **openCV** (cv2), la librairie ordonne les canaux dans l'ordre <span style=\"color:blue\">b</span>, <span style=\"color:green\">v</span>, <span style=\"color:red\">r</span> au lieu du conventionnel <span style=\"color:red\">r</span>, <span style=\"color:green\">v</span>, <span style=\"color:blue\">b</span>.\n",
    "\n",
    "> Dans la majeure partie du TP, nous travaillerons avec des valeurs de pixels comprises entre 0 et 1 pour des images de type **np.float32**. Certaines fonctions spécifiques attendent cependant des valeurs comprises entre 0 et 255, pour des images de type np.uint8. Pour vous faciliter le travail, nous fournissons deux fonctions **f2int** et **int2f** qui se chargeront de faire la conversion d'un type vers l'autre (voir cellule de code ci-dessus).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "La clarté d'une image est définie par:\n",
    "$$\n",
    "c = \\frac{1}{2}(\\max(r, v, b) + \\min(r, v, b))\n",
    "$$\n",
    "\n",
    "Calculez la clarté de l'image et affichez-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Dans la suite du TP, nous essayerons de détecter les contours dans l'image. Les différentes méthodes vues en cours ont tendance à être sensibles. Or, dans le cas présent le pelage du chat peut-être assimilé à un bruit poivre et sel dense. Quel type de filtre faut-il utiliser pour l'atténuer? Filtrez la clarté avec ce filtre en utilisant une fenêtre de taille 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Important** Pour les prochaines questions, nous allons comparer différentes techniques de détection des contours. Pour cela, nous partirons de l'image de clarté filtrée à la question précédente dans toutes les questions suivantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Calculez et affichez sur deux graphiques adjacent (subplots):\n",
    "- L'image du gradient horizontal\n",
    "- L'image du gradient vertical\n",
    "\n",
    "Sur un troisième graphique (nouvelle figure), affichez également la magnitude du gradient.\n",
    "\n",
    "> Pour calculer les gradients, vous devez définir vous-mêmes les masques de convolution. Pour la convolution en elle-même, utilisez la fonction **scipy.signal.convolve2d**\n",
    "```python\n",
    "convolved = scipy.signal.convolve2d(img, mask, mode='same')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Refaites la même expérience, mais cette fois en préfiltrant l'image avec un filtre Gaussien d'écart-type $\\sigma=1$. Vous devez construire vous-même le masque Gaussien (vous ne pouvez pas utiliser cv2.GaussianBlur), en justifiant la taille du masque (en fonction de $\\sigma$).\n",
    "Que se passe-t-il lorsqu'on fait varier sigma?\n",
    "\n",
    "> On rappelle qu'une fonction Gaussienne 2D est donnée par \n",
    "$$G(x, y)=A e^{\\frac{-(x²+y²)}{2\\sigma²}}$$\n",
    "où $A$ est une constante permettant d'assurer que l'aire sous la gaussienne est bien égale à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "Afin d'extraire des contours de la magnitude des gradients, nous allons utiliser la méthode d'Otsu que vous allez devoir implémenter.\n",
    "Complétez la fonction suivante:\n",
    "```python\n",
    "def seuillage_otsu(img):\n",
    "    assert img.dtype==np.uint8, \"L'image doit être de type uint8\"\n",
    "    thresholds = np.unique(img)\n",
    "    hist, bins = np.histogram(img, np.arange(256))\n",
    "    bins = bins[:-1]\n",
    "    hist = hist/img.size\n",
    "    nu = 0\n",
    "    for k in thresholds:\n",
    "        hist_c1  = hist[:k] # Histogramme du cluster 1\n",
    "        hist_c2  = hist[k:] # Histogramme du cluster 2\n",
    "        P1_k = ... # Probabilité d'appartenir au cluster 1\n",
    "        P2_k = ... # A compléter\n",
    "        if P1_k==0:\n",
    "            continue\n",
    "        if P2_k==0:\n",
    "            break\n",
    "        m1_k =  np.sum(bins[:k]*hist_c1) / P1_k.astype(np.float32) # Calcul de la moyenne sur le cluster 1\n",
    "        m2_k =  ... # A compléter\n",
    "        var_interclasse = ... # A compléter\n",
    "        if var_interclasse>nu:\n",
    "            threshold = k\n",
    "            nu = var_interclasse\n",
    "    image_seuillee = ... # À completer\n",
    "    return image_seuillee\n",
    "```\n",
    "Qui prend une image monochrome en paramètre et effectue un seuillage automatique selon la méthode d'Otsu. \n",
    "\n",
    "> Attention, pour la méthode d'Otsu, l'image doit-être de type uint8.\n",
    "\n",
    "Comparez l'effet de la fonction sur la magnitude de gradients avec préfiltrage gaussien et sans. Qu'observez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Vous allez maintenant expérimenter la détection de contours par la méthode de Marr-Hildreth. On rappelle les étapes de la méthode:\n",
    "* L'image est filtrée avec une gaussienne (fixée par $\\sigma$)\n",
    "* On calcule son Laplacien\n",
    "* On cherche les passages par zéros du Laplacien. On conserve ceux correspondant à un écart absolu supérieur à un seuil $t<1$\n",
    "\n",
    "> Le code de la fonction cherchant les passages par zéros vous est fourni. Elle attend en paramètre une image Laplacien et un seuil. \n",
    "\n",
    "\n",
    "Affichez les contours pour $\\sigma=5$ et un seuil égal à 0.005. Pour le calcul du Laplacien, vous devez créer vous-même le filtre correspondant.\n",
    "Testez la détection des contours pour différentes valeurs de sigma et de seuil et indiquez l'effet de ces deux paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passage_par_zeros(img, seuil):\n",
    "    out = np.zeros_like(img)\n",
    "    for i in range(1, img.shape[0]-1):\n",
    "        for j in range(1, img.shape[1]-1):\n",
    "            ec = 0\n",
    "            if img[i-1, j]*img[i+1, j] < 0: # y\n",
    "                ec = max(ec, np.abs(img[i+1, j]-img[i-1, j]))\n",
    "            if img[i, j-1]*img[i, j+1] < 0: # x\n",
    "                ec = max(ec, np.abs(img[i, j+1]-img[i, j-1]))\n",
    "            if img[i-1, j-1]*img[i+1, j+1] < 0: # diag\n",
    "                ec = max(ec, np.abs(img[i+1, j+1]-img[i-1, j-1]))\n",
    "            if img[i+1, j-1]*img[i-1, j+1] < 0: # other diag\n",
    "                ec = max(ec, np.abs(img[i+1, j-1]-img[i-1, j+1]))\n",
    "            \n",
    "            out[i, j] = ec\n",
    "    \n",
    "    threshold = seuil*np.max(out)\n",
    "    return out>threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Enfin, pour compléter votre tour d'horizon des méthodes de détection de contours, vous allez utiliser la méthode de Canny. L'implémentation n'est pas demandée: vous pouvez vous servir de la méthode d'**openCV** de la manière suivante:\n",
    "\n",
    "```python\n",
    "edges_canny = cv2.Canny(clarte, min_hysteresis, max_hysteresis) # clarte doit être en uint8\n",
    "```\n",
    "où min_hysteresis, max_hysteresis représentent respectivement les seuils bas et haut du filtrage par hystérésis.\n",
    "En partant d'un seuil haut à 100, comparez l'effet de différentes valeurs de seuils bas et discutez du résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "Affichez sur un subplots 2x2 les contours obtenus (Otsu sur gradient sans gaussienne et avec gaussienne, avec la méthode de Marr-Hildreth et avec la méthode de Canny). Commentez leurs effets respectifs et leur flexibilité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2\n",
    "\n",
    "Cette partie manipule les images couleurs. Repartez donc de l'image chargée à la toute première question de la partie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "Chargez l'image **chat.png**, filtrez-la avec un filtrage médian de taille 9, convertissez-la en valeur flottantes et affichez-la. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une photographie contient beaucoup plus de couleurs qu'un dessin. Nous allons effectuer une opération de **postérisation** consistant à réduire le nombre de couleurs contenues dans une image. Nous allons pour cela comparer différentes approches.\n",
    "\n",
    "### Postérisation naive\n",
    "\n",
    "Pour cette méthode, on recense toutes les N couleurs distinctes contenues dans l'image sous la forme d'un tableau $T_1$ de taille $N\\times 3$. Par la suite, on ne garde que les K couleurs les plus présentes dans l'image de telle sorte à obtenir un tableau $T_2$ de taille $K \\times 3$. \n",
    "\n",
    "Pour chaque pixel de l'image originale, on remplace alors sa couleur par celle qui lui est la plus proche dans le tableau $T_2$. La notion de proximité est définie en utilisant la distance euclidienne.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "Implémentez la fonction\n",
    "```python \n",
    "def recenser_couleurs(img):\n",
    "    ...\n",
    "    return couleurs_uniques, comptes \n",
    "\n",
    "```\n",
    "Qui renvoie un tableau de couleurs uniques dans une image ainsi que le nombre de pixels associé à chacune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "Complétez les fonctions:\n",
    "\n",
    "```python\n",
    "def distance_euclienne(col1, col2):\n",
    "    \"\"\"\n",
    "    Cette fonction prend en entrée deux tableaux de couleurs et renvoie le tableau des distances entre chacune d'entre elles\n",
    "    :param col1: Tableau de taille Nx3\n",
    "    :param col2: Tableau de taille Mx3\n",
    "    :return d: Tableau des distances euclidiennes de taille NxM\n",
    "\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return d\n",
    "\n",
    "def posterisation_naive(img, K=32):\n",
    "    h, w, c = img.shape\n",
    "    col_uniques, comptes = recenser_couleurs(img)\n",
    "    T2 = ... # A compléter: on ne garde que K les couleurs de col_uniques les + présentes\n",
    "    distances = distance_euclienne(T2,  img.reshape(-1, c))\n",
    "    indices_d_minimale = ... # On récupère pour chaque pixel l'indice qui va nous donner la nouvelle couleur dans T2.\n",
    "    posterisation = ...\n",
    "    return posterisation.reshape(h, w, c)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "Testez et affichez le résultat de la fonction avec K=64. Qu'observez-vous et qu'en concluez-vous sur la postérisation naive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "Pour corriger les défauts de la postérisation naive, nous allons utiliser une manière plus sophistiquée de réduire le nombre de couleurs. Plutôt que ne garder que les plus présentes, nous allons regrouper chaque couleur en K paquets (appelés clusters) de telle sorte que chaque paquet contiennent les couleurs qui lui sont les plus proches. Notre nouveau tableau $T2$ sera alors constitué des moyennes de chaque paquet. Cet algorithme est appelé *K-moyennes* (K-mean) et il est fondamental en IA. \n",
    "\n",
    "Mais pas de panique, vous n'avez pas à l'implémenter! Vous pouvez simplement utiliser la version fournie par la librairie scipy:\n",
    "```python\n",
    "from scipy.cluster.vq import kmeans\n",
    "T2 = kmeans(T1, K)[0] # K est le nombre de couleurs que l'on souhaite garder, T1 le tableau de couleurs uniques.\n",
    "```\n",
    "\n",
    "Implémentez la fonction\n",
    "```python\n",
    "def posterisation_kmeans(img, K=8):\n",
    "    ...\n",
    "```\n",
    "De telle sorte à utiliser l'algorithme *kmeans* pour le calcul de T2. Affichez les résultats pour K=2,K=8 et K=64. Qu'en concluez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "\n",
    "Dans les cas précédents, on a postérisé l'image sans considérations sur l'importance de certaines couleurs par rapport à d'autres. Cependant en général, sur un dessin, une palette de couleurs contient beaucoup plus de teintes différentes que de saturations ou d'intensités différentes (dans une boîte de crayon de couleur, il existe en général une dizaine de teinte différentes mais rarement plus de deux saturations et/ou intensités par teinte). \n",
    "\n",
    "Nous allons mimer ce phénomème en postérisant nos canaux indépendamment. En vous inspirant des questions précédentes, implémentez la fonction:\n",
    "```python\n",
    "def posterize_grayscale(canal, K=8):\n",
    "    ...\n",
    "```\n",
    "qui permet de postériser un seul canal (par la méthode kmean).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "Nous allons utiliser un espace de couleurs très similaires au HSI qui est le HSV (Hue/Saturation/Value). \n",
    "Pour convertir une image RGB en HSV et réciproquement, utilisez la fonction opencv:\n",
    "```python\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "```\n",
    "Affichez les trois canaux H, S et V séparément et commentez le résultat. Dans quels intervalles de valeurs se situent chaque canal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17\n",
    "Postérisez chaque canal indépendamment de telle sorte que:\n",
    "- Le canal de teinte ne contienne plus que 8 éléments différents\n",
    "- Le canal de saturation n'en contienne plus que 3\n",
    "- Le canal de valeur n'en contienne plus que 3\n",
    "\n",
    "Puis reconstruisez l'image à partir des canaux postérisés.\n",
    "\n",
    "Quel est le nombre théorique maximal de couleurs uniques que peut contenir l'image avec ces contraintes? En pratique, combien de couleurs contient votre image après cette postérisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18\n",
    "Et pour finir, complétons notre dessin en ajoutant les contours que nous avons déjà calculés dans la partie 1 à notre image!\n",
    "> Pour faire cela, vous pouvez aussi bien utiliser l'indexation (mettre à 0 les valeurs de contours sur l'image), la multplication élément par élément ou encore un bitwise_xor... Libre à vous de choisir la méthode qui vous arrange!\n",
    "\n",
    "\n",
    "Créez quatre subplots et affichez les différents contours (gradients, canny, méthode LoG...) en noir par dessus l'image postérisée calculée à la question précédente.\n",
    "Laquelle vous paraît fournir le meilleur résultat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19\n",
    "En réalité, les traits d'un dessin sont rarement parfaitement noirs, leurs couleurs peuvent dépendre de leurs épaisseurs et de la couleur de l'objet qu'ils délimitent.\n",
    "\n",
    "En prenant en compte ces deux considérations, proposez-une amélioration de l'effet de nos contours pour accentuer l'illusion d'un dessin. Vous pouvez combiner à votre guise différents résultats obtenus précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question bonus\n",
    "\n",
    "On vous fournit une extension de l'image précédente, à laquelle on a ajouté un dernier effet. Chargez l'image **dessin_chaton.png** et affichez-la.\n",
    "Pouvez-vous identifier l'effet ajouté? Proposez une manière simple de la reproduire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('py38')",
   "language": "python",
   "name": "python37764bitpy386272c69a2da84f6ab9703b5e5560986c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
